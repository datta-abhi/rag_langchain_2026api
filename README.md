# Retrieval-Augmented Generation (RAG) Pipeline using LangChain (2026 API Syntax)
This project implements a production-style Retrieval-Augmented Generation (RAG) pipeline built with the latest LangChain (2026 API updates). It demonstrates how to construct an end-to-end retrieval and generation workflow using modern LangChain abstractions, including updated model initialization, prompt templates, retrievers, and runnable chains.

Key Components

**Document Ingestion & Preprocessing** – Text loading, chunking, and metadata handling.

**Embedding Generation** – Vector representations using configurable embedding models.

**Vector Store Integration** – Efficient similarity search for contextual retrieval.

**Retriever Abstraction** – Modular retrieval layer compatible with LangChain’s updated interfaces.

**LLM Integration** – Structured prompt chaining using the latest ChatModel initialization patterns.

**Composable Runnables** – End-to-end orchestration using LangChain’s runnable pipelines.

### Objectives

Provide a clean reference implementation aligned with LangChain 2026 syntax changes.

Showcase modular, extensible design suitable for scaling to production.

Serve as a foundation for domain-specific knowledge assistants and document-aware chatbots.

This repository is ideal for practitioners looking to understand modern RAG architecture patterns using the latest LangChain framework conventions.
